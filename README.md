# Word2Vec
This code will walk you through the basic steps for computing semantic similarity using the Word2Vec model. 
Word2Vec represents each word as a high-dimensional vector, allowing you to compute the semantic similarity between words using vector operations.


First, clone this repository to your local machine or lab server.

Then, Download the Pre-trained Word2Vec Model. This project uses the Google News Word2Vec model trained on 100 billion words.

You can download it here (warning: large file ~1.5GB):

ðŸ“¥ https://github.com/mmihaltz/word2vec-GoogleNews-vectors

After downloading, extract the file and place it in the appropriate folder in your cloned repository.
